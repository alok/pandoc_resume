# Alok Singh

<alokbeniwal@gmail.com> • 408-421-5658 •
[github.com/alok](https://www.github.com/alok/)

### Experience

Deep Learning Scientist , Movano Inc. Pleasanton, CA (Aug 2023-):

I am doing deep learning on health data to predict metrics like blood
pressure, sleep, and blood glucose. I also gleaned valuable insight on
the workings of contemporary medical devices.

**Research Resident, Redwood Research** (2023)

I used my reinforcement and deep learning expertise to mechanistically
interpret AlphaGo and probe its adversarial exploitability. We find that
AlphaGo often decides its final move very
[early](https://www.lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2)
in its hidden layers.

**Deep Learning Scientist, Lawrence Berkeley National Lab** (2019-2022)

My first project at the lab involved leading a team to replace (slow)
classical climate simulation models with GANs and super-resolution.
Simulation time dropped from 4 hours to 1 second. This work was
published at NeurIPS.

Within a year, I led a team of 10 researchers and programmers for a \$2M
[ARPA-E DIFFERENTIATE
project](https://arpa-e.energy.gov/technologies/projects/deep-learning-and-natural-language-processing-accelerated-inverse-design).

I devised and directed us in building a differentiable electromagnetic
simulator in Julia. It evolved meshes to have specified desirable
optical properties---a hybrid of flexible deep learning and rigid
symbolic equations. It guided a
[laser](https://www.youtube.com/watch?v=VraR6LVr0RA) to ablate materials
to specific emissivities (relevant e.g., to solar panels).

**Machine Learning Consultant, Papert Labs** (2018):

I consulted with Silicon Valley financial startups on using machine and
reinforcement learning.

**Recurse Center** (2017): A self-directed programmer's retreat. I
taught myself reinforcement learning and [implemented many
algorithms](https://github.com/alok/rl_implementations/) and gave 2
talks.

Data Scientist, Radius Intelligence · Internship (2015) San Francisco,
CA

I looked at customer data and incorporated it with our own. I also wrote
ETL code and helped debug Spark.I looked at customer data and
incorporated it with our own. I also wrote ETL code and helped debug
Spark

### Talks, Papers, and Projects

[Generalization Properties of Machine Learning Based Weather Model
Downscaling](https://ai4earthscience.github.io/iclr-2020-workshop/papers/ai4earth25.pdf),
ICLR 2020

[Numerical Weather Model
Super-Resolution](https://ml4physicalsciences.github.io/2019/files/NeurIPS_ML4PS_2019_75.pdf),
NeurIPS 2019

[Detecting Spiky Corruption in Markov Decision
Processes](https://arxiv.org/pdf/1907.00452.pdf), IJCAI 2019

[How to differentiate a discontinuous
function](https://www.youtube.com/watch?v=YP-iTs5m3X0)

[A reinforcement learning environment for mathematical reasoning via
program synthesis](https://arxiv.org/pdf/2107.07373.pdf). This used LLMs
to output math proofs (checked by the [Lean Theorem
Prover](https://leanprover.github.io/)) and was improved by
reinforcement learning.

[BFF](https://www.textbff.com/): Built an iMessage app around ChatGPT
with 10,000 users (Dec 2022)

### Skills

-   DL frameworks and libraries - PyTorch, JAX, Tensorflow, CUDA, cuDNN,
    cuBLAS
-   Machine Learning/Deep Learning algorithms such as GPR, SVM, RF,
    XGBoost, CNN, RNN
-   Time-series modeling using LSTM, Transformers
-   Programming/Scripting Languages - Python, C++, Rust, Julia, Bash,
    Lean
-   Deep Reinforcement Learning (PPO, SAC, Curiosity), LLMs, Automated
    Theorem Proving
-   Research publications in major conferences (NeurIPS, ICLR, IJCAI)

### Education

2013 - 2017

:   **Bachelor's, Mathematics, UC Berkeley**
